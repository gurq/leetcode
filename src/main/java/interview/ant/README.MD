### 解题思路

#### 1. 一句话概括

生产者消费者模式 + forkJoinPool + TreeMap

#### 2. 审题

> 功能要求：
> 1.对文件夹下面所有文件的内容进行合并排序，输出按照分组升序排序之后，
> 每个分组下面的最小指标值。
> 
> 非功能要求：
> 3.文件读取和排序要求并发作业，文件读取只要产生了数据，
> 就可以把数据交给排序线程进行消费，计算最小值。

2.1 本来其实最大也就100*100k=10M，直接扔set里stream groupBy完事，
但是后面要求一边读一边排序，那就只能一边读一边往有序集合里放

2.2 要分组，那肯定得是map型的，又要key有序，那就只能treeMap了，
这里只有一个线程在写，所以没有线程安全问题，
如果说这题扩展一下，值也要有序，那值就用基于大顶堆/小顶堆的PriorityQueue

```
都写完了自己做review的时候想到，如果还需要性能优化的话，不用treeMap，
因为treeMap每次存的时候都排序了，查询也没有直接算hash来的快，
就直接用hashMap，存的时候把groupId存在线程安全的Collections.synchronizedSet里，
到最后要打印结果的时候，给set放到list里sort一下，直接从hashMap取就行，按理说比用treeMap快
但是现在做完已经2点了，明天还有3场面试，就不再优化了，就先这样哈
```


> 非功能要求：
> 2.查找要求有独立线程来执行，直接 **【消费】** 读取线程池产生的内存数据结构。
> 3.文件读取和排序要求并发作业，文件读取只要 **【产生】** 了数据，就可以把数据交给排序线程进行 **【消费】** ，计算最小值。

2.3 提示的很明显了，生产者消费者模式

> 非功能要求
> 1.文件读取要有线程池来执行，线程池的大小固定为10，文件内容需要存储到指定的数据结构当中。

2.4 像这种有明确工作数的，多个线程协同工作，不会一边工作一边来新任务的，我都会优先选择forkjoinpool，
工作窃取这个设计理念太领先了